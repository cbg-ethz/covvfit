{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Covvfit: Variant fitness estimates from wastewater data","text":"<p>Covvfit is a framework for estimating relative growth advantages of different variants from deconvolved wastewater samples. It consists of command line tools, which can be included in the existing workflows and a Python package, which can be used to quickly develop custom solutions and extensions.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>Covvfit can be installed from the Python Package Index:</p> <pre><code>$ pip install covvfit\n$ covvfit check\n</code></pre> <p>For an example how to analyze the data using the provided command line tool, see this tutorial.</p> <p>For more detailed installation instructions, including troubleshooting, see the installation guide.</p>"},{"location":"#faq","title":"FAQ","text":"<p>How do I run Covvfit on my data?</p> <p>We recommend to start using Covvfit as a command line tool, with the tutorial available here. </p> <p>What data does Covvfit use?</p> <p>Covvfit uses deconvolved wastewater data, accepting relative abundances of different variants measured at different locations and times. Tools such as LolliPop or Freyja can be used to deconvolve wastewater data. </p> <p>Note, however, that the deconvolution procedure should not smooth abundance results. For more information on this topic, see here.</p> <p>Can Covvfit predict emergence of new variants?</p> <p>No, Covvfit explicitly assumes that no new variants emerge in the considered timeframe, so its predictions are unlikely to hold on longer timescales. The underlying model also cannot take into account changes in the transmission dynamics or immune response, so that it cannot predict the effects of vaccination programs or lockdowns.</p> <p>How can I contact the developers?</p> <p>In case you find a bug, want to ask about integrating Covvfit into your pipeline, or have any other feedback, we would love to hear it via our issue tracker! In this manner, other users can also benefit from your insights.</p> <p>Is there a manuscript associated with the tool?</p> <p>Yes! The reference for this tool is:</p> <p>David Dreifuss, Pawe\u0142 Piotr Czy\u017c, Niko Beerenwinkel. Learning and forecasting selection dynamics of SARS-CoV-2 variants from wastewater sequencing data using Covvfit. medRxiv 2025.03.25.25324639; doi: https://doi.org/10.1101/2025.03.25.25324639</p>"},{"location":"cli/","title":"Command line workflow","text":"<p>We assume that the Covvfit tool has been installed properly (see the installation guide). Covvfit takes as an input a data frame containing deconvolved values. Below we describe how to download an example data set.</p> <p>However, if you have your own data, you can deconvolve them using the following tools:</p> <ul> <li>LolliPop: follow these instructions on how to run LolliPop. (Note that the smoothing can bias the results, so you may need to deconvolve the data again, if you used smoothing.)</li> <li>Freyja: follow these instructions to assemble the outputs into a data frame.</li> </ul> <p>In this tutorial we will work with example data, which have already been deconvolved and assembled into a suitable data frame.</p>"},{"location":"cli/#the-data","title":"The data","text":"<p>What is the suitable data? We assemble the deconvolved variant abundance estimates into a data frame with four columns, representing location (the region or city where the data were obtained), date (when the sample was collected), variant and deconvolved proportions.</p> <p>Example data can therefore look as follows: <pre><code>location  variant  date        proportion\nGE        KP.2     2025-02-04  0.363\nGE        KP.3     2025-02-04  0.141\nGE        XEC      2025-02-04  0.326\nZH        KP.2     2025-02-09  0.251\nZH        XEC      2025-02-09  0.507\n</code></pre></p> <p>where <code>location</code> column refers to Geneva or Zurich treatment plants, <code>variant</code> represent variant name corresponding to the right <code>proportion</code> obtained from a sample collected at date <code>date</code>.  Note that a single deconvolved sample corresponds to several rows in a data frame, representing the abundance estimates for different variants on that day.</p> <p>The example data can be downloaded from this link. Create the new directory and save the data there as <code>example-data.tsv</code>. A larger data set, which was used in the publication, is available on Zenodo.</p>"},{"location":"cli/#running-covvfit","title":"Running Covvfit","text":"<p>We have installed the package and downloaded the data. Using the <code>cd</code> command, navigate to the directory where the data have been downloaded. We can run the tool using:</p> <pre><code>$ covvfit infer --input example-data.tsv --output example-output -v KP.2 -v KP.3 -v XEC\n</code></pre> <p>After a few seconds, we should see a new directory, <code>example-output</code>, containing the analysis results. To interpret the arguments provided to the tool:</p> <ul> <li><code>--input</code>: the file with example data;</li> <li><code>--output</code>: the directory that the tool will create and populate with the analysis results;</li> <li><code>-v</code>: used to specify the investigated variants. All the variants not included in the list are merged into an \"other\" variant.  </li> </ul> <p>What files in the <code>example-output</code> directory were created? By default, we should see the following:</p> <ul> <li><code>figure.pdf</code> (or <code>figure.png</code>): the figure with the fit to the available data as well as forecasts;</li> <li><code>results.yaml</code>: the relative fitness advantages of different variants in the analysis over the \"other\" variant;</li> <li><code>pairwise_fitnesses.csv</code>: the relative fitness advantages between each pair of variants.</li> <li><code>log.txt</code>: log of the computations performed by the tool.</li> </ul>"},{"location":"cli/#interpreting-the-figure","title":"Interpreting the figure","text":"<p>The figure will look as follows:</p> <p></p> <p>We see the variant abundances for each location, together with the model fit, as well as model predictions over the coming weeks (marked with dashed lines in the shaded region).</p>"},{"location":"cli/#more-control-over-input-arguments","title":"More control over input arguments","text":"<p>The above example is very simple, as the example data have been formatted according to our default naming conventions. How can we run the tool on the data which is formatted differently? For example, it's not a TSV file (separated using the TAB character), but rather a CSV file (separated using the comma)? Or the column names are different?</p> <p>We can control these settings using additional arguments. We can print help using:</p> <pre><code>$ covvfit infer --help\n</code></pre> <p>which prints the following message:</p> <pre><code> Usage: covvfit infer [OPTIONS]                                                                                                                                                                                                               \n\n Runs growth advantage inference.                                                                                                                                                                                                                                                                                                                                                                                                                        \n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --input             -i      TEXT     CSV with deconvolved data [default: None] [required]                                                                                                                                               \u2502\n\u2502 *  --output            -o      TEXT     Output directory [default: None] [required]                                                                                                                                                        \u2502\n\u2502    --config            -c      TEXT     Path to the YAML file with configuration. [default: None]                                                                                                                                          \u2502\n\u2502    --var               -v      TEXT     Variant names to be included in the analysis. Note: overrides the settings in the config file (--config). [default: None]                                                                          \u2502\n\u2502    --loc               -l      TEXT     Location names to be included in the analysis. Note: overrides the settings in the config file (--config). [default: None]                                                                         \u2502\n\u2502    --separator         -s      TEXT     Data separator used to read the input file. By default read from the config file (if not specified, the TAB character). [default: None]                                                            \u2502\n\u2502    --max-days                  INTEGER  Number of the past dates to which the analysis will be restricted [default: 240]                                                                                                                   \u2502\n\u2502    --date-min                  TEXT     Minimum date to start load data in format YYYY-MM-DD. By default calculated using `--max_days` and `--date-max`. [default: None]                                                                   \u2502\n\u2502    --date-max                  TEXT     Maximum date to finish loading data, provided in format YYYY-MM-DD. By default calculated as the last date in the CSV file. [default: None]                                                        \u2502\n\u2502    --horizon                   INTEGER  Number of future days for which abundance prediction should be generated [default: 60]                                                                                                             \u2502\n\u2502    --horizon-date              TEXT     Date until when the predictions should occur, provided in format YYYY-MM-DD. By default calculated using `--horizon` and `--date-max`. [default: None]                                             \u2502\n\u2502    --time-spacing              INTEGER  Spacing between ticks on the time axis in months [default: None]                                                                                                                                   \u2502\n\u2502    --variant-col               TEXT     Name of the column representing observed variant [default: variant]                                                                                                                                \u2502\n\u2502    --proportion-col            TEXT     Name of the column representing observed proportion [default: proportion]                                                                                                                          \u2502\n\u2502    --date-col                  TEXT     Name of the column representing measurement date [default: date]                                                                                                                                   \u2502\n\u2502    --location-col              TEXT     Name of the column with spatial location [default: location]                                                                                                                                       \u2502\n\u2502    --help                               Show this message and exit.                                                                                          \n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>We see that the separator can be changed by using the <code>--separator</code> (or <code>-s</code> for short) argument. Similarly, the column names can be set using <code>--variant-col</code>, <code>--proportion-col</code> etc. argument</p>"},{"location":"cli/#navigating-space-and-time","title":"Navigating space and time","text":"<p>Similarly as <code>-v</code> controls the list of variants in the analysis, the <code>--loc</code> flag controls the locations included. If no <code>--loc</code> flag is specified, we use all the locations found in the data frame (in the example above, it is equivalent to <code>--loc GE --loc ZH</code>). However, to restrict the analysis only to the data from Geneva, you can run <code>--loc GE</code>.</p> <p>Additionally, one can control the time range. Use e.g., <code>--date-min 2024-08-20</code> to load only the data collected on <code>2024-08-20</code> and onwards or <code>--date-max 2025-02-01</code> to truncate the data to <code>2025-02-01</code>. Note that the format used is <code>YYYY-MM-DD</code>. This utility can be useful to understand how much new data affect the predictions and the uncertainty. Additionally, <code>--horizon-date YYYY-MM-DD</code> specifies the time interval for which the abundance prediction is issued.</p> <p>However, for regular water surveillance efforts, it may be cumbersome to select the date ranges as specified above. Use <code>--max-days 240</code> to restrict the data to the newest sample and the 240 days of data collected before it. Similarly,<code>--horizon 60</code> specifies that the predictions should be issues for the 60 days after the last sample was collected.</p> <p>Finally, <code>--time-spacing 2</code> controls that the ticks on the time axis in the plot should be spaced every two months. While this utility does not affect the analysis, it can significantly affect the plot readability.</p>"},{"location":"cli/#using-configuration-files","title":"Using configuration files","text":"<p>Specifying a long list of variants using <code>-v</code> flag can be inconvenient. We can use a configuration file to specify it in a more convenient fashion.</p> <p>Open a new file, <code>config.yaml</code> and specify the following:</p> <pre><code># This is the content of the config.yaml\nvariants:\n  - KP.2\n  - KP.3\n  - XEC\n</code></pre> <p>Now we can run the tool using:</p> <pre><code>$ covvfit infer --input example-data.tsv --output example-output-with-config --config config.yaml\n</code></pre> <p>so that the tool will load the variants from <code>config.yaml</code>!</p> <p>In fact, <code>config.yaml</code> can be used to achieve more fine-grained control the analysis and the output figure.</p> <pre><code>variants:\n- XEC\n- KP.2\n- KP.3\nlocations:\n  - GE\n  - ZH \n# Alternatively, comment out the `locations` above and uncomment the following line, to include all locations by default:\n# locations: null\nanalysis:\n  data_separator: \"\\t\"\n  n_starts: 10  # Number of restarts in the optimization\n  other_threshold: null  # Specify to e.g., 0.7 to ignore the samples where \"other\" variant achieves at least 0.7 abundance\nplot:\n  backend: null  # Matplotlib backend.\n  dimensions:    # Plot visuals\n    bottom: 0.5\n    dpi: 350\n    hspace: 0.5\n    left: 1.0\n    panel_height: 1.5\n    panel_width: 4.0\n    right: 1.5\n    top: 0.7\n    wspace: 1.0\n  dpi: 500       # Plot resolution\n  extensions:    # Figure will be generated using the follosing extensions \n  - png\n  - pdf\n  prediction:\n    linestyle: ':'\n    region_alpha: 0.1\n    region_color: grey\n  time_spacing: 2          # The time spacing, can be overridden using the command line `--time-spacing` argument\n  variant_colors:          # The colors of different variants\n    KP.2: '#876566'\n    KP.3: '#331eee'\n    XEC: '#a2a626'\n</code></pre>"},{"location":"developers/","title":"For developers","text":""},{"location":"developers/#installation","title":"Installation","text":"<p>Clone the repository using</p> <pre><code>$ git clone git@github.com:cbg-ethz/covvfit.git\n</code></pre> <p>Then, create a new Python environment, e.g., using Micromamba: <pre><code>$ micromamba create -n covvfit -c conda-forge python=3.11\n</code></pre></p> <p>Install the package in editable mode together with the developer utilities:</p> <pre><code>$ pip install poetry\n$ poetry install --with dev\n$ pre-commit install\n</code></pre>"},{"location":"developers/#testing","title":"Testing","text":"<p>We use Pytest to write the unit tests. The unit tests are stored in <code>tests/</code> directory. After the installation you can verify whether the unit tests are passed by running</p> <pre><code>$ pytest tests\n</code></pre>"},{"location":"developers/#documentation","title":"Documentation","text":"<p>We write the documentation using Mkdocs in the <code>docs/</code> directory. Apart from tutorials, we generate the API description directly from function docstrings.</p> <p>Use</p> <pre><code>$ mkdocs build\n</code></pre> <p>to see whether the documentation is built properly. Alternatively, to check the documentation in the interactive mode, use</p> <pre><code>$ mkdocs serve\n</code></pre>"},{"location":"installation/","title":"Installation guide","text":""},{"location":"installation/#conventions","title":"Conventions","text":"<p>We assume that the following are available:</p> <ul> <li>A Unix-based shell. For example, the terminal emulator on Linux, BSD, MacOS or the WSL terminal on Windows.</li> <li>A Python 3.11 (or newer) installation. It can be obtained by using e.g., Micromamba.</li> </ul> <p>We use the convention that <code>$</code> represents the command line prompt. For example,</p> <p><pre><code>$ run command\n</code></pre> means that one should type <code>run command</code> into the command line shell.</p>"},{"location":"installation/#installation-instructions","title":"Installation instructions","text":"<p>To install Covvfit, ensure that you have Python installed and run:</p> <pre><code>$ pip install covvfit\n</code></pre> <p>This installs:</p> <ul> <li>The command line program <code>covvfit</code>, which can be run on deconvolved data to estimate fitness advantages. </li> <li>The Python package <code>covvfit</code>, which can be used to create more complex automated workflows or employed to build other tools.</li> </ul>"},{"location":"installation/#checking-if-the-installation-works","title":"Checking if the installation works","text":"<p>Run <pre><code>$ covvfit check\n</code></pre></p> <p>If the program outputs <code>[Status: OK]</code>, then the tool is installed properly.</p> <p>However, if you see any message with <code>[Status: Error]</code>, then it means there is a problem with installation.</p> <p>It is possible, that an incompatible version of the JAX package has been downloaded. In this case, consult this installation guide. In any other case, please report the problem by filling an issue on our bug tracker, including the output in the description of the problem.</p>"},{"location":"models/","title":"Statistical models","text":"<p>Here, we explain the statistical models used in the Covvfit tool. For more details, see the manuscript:</p> <p>D. Dreifuss, P. Czy\u017c, N. Beerenwinkel, Learning and forecasting selection dynamics of SARS-CoV-2 variants from wastewater sequencing data using Covvfit (2025; in preparation). URL: https://github.com/cbg-ethz/covvfit</p> <p>The models are composed of two components:</p> <ul> <li>The growth model used to describe how the abundances increase or decrease, basing on competition between different variants. This model links some interpretable parameters (such as the growth advantages) with idealised (unobserved) abundances, \\(p(t)\\).</li> <li>The noise model connecting idealised abundances \\(p(t)\\) with deconvolved values \\(y(t)\\), which are subject to some noise.</li> </ul>"},{"location":"models/#growth-model","title":"Growth model","text":""},{"location":"models/#single-location-model","title":"Single-location model","text":"<p>We consider V competing variants, numbered between 1, ..., V present in the population. At time \\(t\\) the relative abundances of the variants are represented by a vector \\(p (t) = (p_1(t), p_2(t), ..., p_V(t))\\). We assume survival-of-the fittest type of selection dynamics, where the \\(i\\)-th variant has a fitness value \\(f_i\\), which is fixed in time, and the relative abundances change at a rate proportional to their fitness advantage over the average value:</p> \\[ \\frac{\\mathrm d}{\\mathrm dt}p_i(t)= p_i(t)\\left(f_i - \\sum_{j=1}^V p_j(t) f_j \\right).\\] <p>In this model, the selection advantage of variant \\(X_i\\) over variant \\(X_j\\) is given by \\(s_{ij}=f_i-f_j\\). Note that the model dynamics is determined only by the relative selection advantages, rather than the fitness values \\(f_i\\), making the problem non-identifiable: adding a constant to all fitness values does not change the dynamics of the model. Hence, without loss of generality, we set \\(f_1=0\\), to avoid this identifiability issue.</p> <p>This set of ordinary differential equations has the analytical solution </p> \\[ p_i(t)=\\frac{\\exp(f_i\\cdot t+b_i)}{ \\sum_{j=1}^V \\exp(f_j\\cdot t + b_j)} \\] <p>Where \\(b_1, b_2, ..., b_V\\) are constants given by the initial conditions. Similarly as with fitness values, adding a constant to all \\(b_i\\) does not change the functions \\(p_i(t)\\). We fix \\(b_1 = 0\\).</p>"},{"location":"models/#multiple-location-model","title":"Multiple-location model","text":"<p>The above model can be used to describe a collection of location-specific relative abundance vectors \\(p_k(t)\\), where the index \\(k\\in \\{1,..., K\\}\\) represents a spatial location (e.g., the city or a district connected to one data collection system).</p> <p>We expect that the introduction times of different variants to different locations may be different, which we accommodate by defining location-specific parameters \\(b_{vk}\\). However, if the wastewater sampling locations are located at the same country subject to the same vaccine program and immunization, we suspect that the processes \\(p_k(t)\\) are not entirely independent. We therefore make an assumption that the fitness value does not change across the locations.</p> <p>Note that while we find this assumption plausible in the analysis of the data from the same country, it may not hold when analysing locations subject to different vaccine programs.</p> <p>To summarize, we infer parameters \\(b_{vk}\\) for all variants \\(v\\in \\{1, ..., V\\}\\) and locations \\(k\\in \\{1,..., K\\}\\)  together with fitness values \\(f_1, ..., f_V\\), which are shared between the sampling locations. We use the identifiability constraints \\(f_1 = 0\\) and \\(b_{1k} = 0\\) for all \\(k\\).</p>"},{"location":"models/#noise-model","title":"Noise model","text":"<p>We deconvolute a wastewater sample collected at time point \\(t\\) and location \\(k\\) to obtain the observed relative abundances vector</p> <p>\\(y_k(t) =(y_{1k}(t), ..., y_{Vk}(t))\\), where \\(y_{vk}(t)\\) represents the relative abundance of variant \\(v\\in \\{1, ..., V\\}\\) as obtained in the deconvolution procedure.</p> <p>Due to a small load of viral signal, amplification through next generation sequencing method, and deconvolution procedure, we do not have an explicit generative model linking the ideal abundance value \\(p_k(t)\\), to the deconvolved value \\(y_k(t)\\). Instead, we use the quasi-likelihood approach, where we assume that \\(\\mathbb E[y_k(t)] = p_k(t),\\) and use a covariance function in a generalized linear model corresponding to the scaled multinomial distribution. In this manner, the quasi-likelihood inference allows one to correct the obtained confidence intervals by using the dispersion parameter, which is adapted to capture the variance observed in the data.</p> <p>As both \\(y_k(t)\\) and \\(p_k(t)\\) are probability vectors, we use the quasi-multinomial model, in which the quasi-loglikelihood function is given by</p> \\[ q(f,b)= \\sum_{k=1}^K \\sum_{t=1}^T\\sum_{v=1}^V y_{vk}(t) \\log p_{vk}(t). \\] <p>We numerically optimize it to find the maximum quasi-likelihood estimate \\(\\hat \\theta = (\\hat f, \\hat b)\\).</p>"},{"location":"api/","title":"API Reference","text":"<p>The package is divided into several modules, corresponding to different utilities.</p>"},{"location":"api/#quasimultinomial-model","title":"Quasimultinomial model","text":"<p>The quasimultinomial noise model, which corresponds to the high-level Covvfit utilities. The API is available here.</p> <p>Caution: There are public functions in this submodule, which are being refactored into other modules.</p>"},{"location":"api/#dynamics","title":"Dynamics","text":"<p>The growth models, linking model parameters to outcomes of idealised abundance. The API is available here.</p>"},{"location":"api/#preprocessing","title":"Preprocessing","text":"<p>Data preprocessing utilities, used to load deconvoluted data into the model and reshape them into appropriate data formats. The API is available here.</p>"},{"location":"api/#plotting","title":"Plotting","text":"<p>The plotting utilities.  The API is available here.</p>"},{"location":"api/#numeric","title":"Numeric","text":"<p>General numerical programming utilities. The API is available here.</p>"},{"location":"api/dynamics/","title":"Dynamics","text":"<p>Models predicting the changes in variant abundances over time.</p> <p>Import as</p> <pre><code>from covvfit import dynamics\n</code></pre>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams","title":"<code> covvfit.dynamics.JointLogisticGrowthParams            (tuple)         </code>","text":"<p>This is a model of logistic growth (selection dynamics) in <code>K</code> cities for <code>V</code> competing variants.</p> <p>We assume that the relative growth advantages do not change between the cities, however we allow different introduction times, resulting in different offsets in the logistic growth model.</p> <p>This model has <code>V-1</code> relative growth rate parameters and <code>K*(V-1)</code> offsets.</p> <p>Attrs:</p> <pre><code>relative_growths: relative growth rates, shape `(V-1,)`\nrelative_offsets: relative offsets, shape `(K, V-1)`\n</code></pre>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.n_cities","title":"<code>n_cities: int</code>  <code>property</code> <code>readonly</code>","text":"<p>Number of cities.</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.n_params","title":"<code>n_params: int</code>  <code>property</code> <code>readonly</code>","text":"<p>Number of all parameters in the model.</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.n_variants","title":"<code>n_variants: int</code>  <code>property</code> <code>readonly</code>","text":"<p>Number of variants.</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.__getnewargs__","title":"<code>__getnewargs__(self)</code>  <code>special</code>","text":"<p>Return self as a plain tuple.  Used by copy and pickle.</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.__new__","title":"<code>__new__(_cls, relative_growths, relative_offsets)</code>  <code>special</code> <code>staticmethod</code>","text":"<p>Create new instance of JointLogisticGrowthParams(relative_growths, relative_offsets)</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.__repr__","title":"<code>__repr__(self)</code>  <code>special</code>","text":"<p>Return a nicely formatted representation string</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.from_vector","title":"<code>from_vector(theta, n_variants)</code>  <code>classmethod</code>","text":"<p>Wraps a vector with parameters of shape <code>(dim,)</code> to the model. Note that <code>dim</code> should match the number of parameters.</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.predict_log_abundance","title":"<code>predict_log_abundance(self, timepoints)</code>","text":"<p>Predicts the abundances at the specified time points.</p>"},{"location":"api/dynamics/#covvfit.dynamics.JointLogisticGrowthParams.to_vector","title":"<code>to_vector(self)</code>","text":"<p>Wraps all the parameter into a single vector.</p> <p>Note</p> <p>This function is useful for optimization purposes, as many optimizers accept vectors, rather than tuples.</p>"},{"location":"api/numeric/","title":"Numeric","text":"<p>General numerical programming utilities.</p> <p>It can be imported as: <pre><code>from covvfit import numeric\n</code></pre></p> <p>or</p> <pre><code>import covvfit\n\ncovvfit.numeric.some_function()\n</code></pre>"},{"location":"api/numeric/#optimization","title":"Optimization","text":""},{"location":"api/numeric/#covvfit.numeric.OptimizeMultiResult","title":"<code> covvfit.numeric.OptimizeMultiResult        </code>  <code>dataclass</code>","text":"<p>Multi-start optimization result.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>array of shape <code>(dim,)</code> representing minimum found</p> required <code>fun</code> <code>float</code> <p>value of the optimized function at <code>x</code></p> required <code>best</code> <code>OptimizeResult</code> <p>optimization result (for the best start, yielding <code>x</code>)</p> required <code>runs</code> <code>list</code> <p>all the optimization results (for all starts)</p> required"},{"location":"api/numeric/#covvfit.numeric.jax_multistart_minimize","title":"<code>covvfit.numeric.jax_multistart_minimize(loss_fn, theta0, n_starts=10, random_seed=42, maxiter=10000)</code>","text":"<p>Multi-start gradient-based minimization.</p> <p>Parameters:</p> Name Type Description Default <code>loss_fn</code> <p>loss function to be optimized</p> required <code>theta0</code> <code>ndarray</code> <p>vector of shape <code>(dim,)</code> providing an example starting point</p> required <code>n_starts</code> <code>int</code> <p>number of different starts</p> <code>10</code> <code>random_seed</code> <code>int</code> <p>seed used to perturb <code>theta0</code></p> <code>42</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations per run</p> <code>10000</code> <p>Returns:</p> Type Description <code>result</code> <p>OptimizeMultiResult with the optimization information</p>"},{"location":"api/numeric/#matrix-operations","title":"Matrix operations","text":""},{"location":"api/numeric/#covvfit.numeric.log_matrix","title":"<code>covvfit.numeric.log_matrix(a, threshold=1e-07)</code>","text":"<p>Takes the logarithm of the entries, in a numerically stable manner. I.e., replaces values smaller than <code>threshold</code> with minimum value for the provided data type.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Float[Array, '*shape']</code> <p>matrix which entries should be logarithmied</p> required <code>threshold</code> <code>float</code> <p>threshold used when to not calculate the logarithm</p> <code>1e-07</code> <p>Returns:</p> Type Description <code>log_a</code> <p>matrix with logarithmied entries</p>"},{"location":"api/numeric/#covvfit.numeric.log1mexp","title":"<code>covvfit.numeric.log1mexp(x)</code>","text":"<p>Computes <code>log(1 - exp(x))</code> in a numerically stable way.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Float[Array, '*shape']</code> <p>array</p> required <p>Returns:</p> Type Description <code>log1mexp(x)</code> <p>array of the same shape as <code>x</code></p>"},{"location":"api/numeric/#covvfit.numeric.logsumexp_excluding_column","title":"<code>covvfit.numeric.logsumexp_excluding_column(y, axis=-1)</code>","text":"<p>Compute logsumexp across the given axis for each element, excluding the 'current' element at that axis index.</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>Float[Array, '*batch variants']</code> <p>An array of shape [..., variants, ...].</p> required <code>axis</code> <code>int</code> <p>The axis along which we exclude each index before computing   logsumexp.</p> <code>-1</code> <p>Returns:</p> Type Description <code>Float[Array, '*batch variants']</code> <p>An array of the same shape as <code>y</code>, whose element at index i along <code>axis</code> is the log-sum-exp of all other entries (j != i).</p>"},{"location":"api/plotting/","title":"Plotting","text":"<p>Plotting utilities.</p> <p>Import as:</p> <pre><code>from covvfit import plot\n</code></pre>"},{"location":"api/plotting/#covvfit.plotting._grid.ArrangedGrid","title":"<code> covvfit.plotting._grid.ArrangedGrid        </code>  <code>dataclass</code>","text":"<p>A two-dimensional grid of axes.</p> <p>Attrs</p> <p>fig: Matplotlib figure.</p> <p>one-dimensional array of active axes,</p> <p>with length equal to the number of active plots</p> <p>axes_grid: two-dimensional array of all axes.</p> <p>Note</p> <p>The number of plots in <code>axes_grid</code> is typically greater than the one in <code>axes</code>, as <code>axes_grid</code> contains also the axes which are not active</p>"},{"location":"api/plotting/#covvfit.plotting._grid.ArrangedGrid.map","title":"<code>map(self, func, arguments=None)</code>","text":"<p>Applies a function to each active plotting axis.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Union[Callable[[matplotlib.axes._axes.Axes], NoneType], Callable[[matplotlib.axes._axes.Axes, Any]]]</code> <p>function to be applied. It can have signature func(ax: plt.Axes) if <code>arguments</code> is None, which modifies the axis in-place.</p> <p>If <code>arguments</code> is not None, then the function should have the signature func(ax: plt.Axes, argument) where <code>argument</code> is taken from the <code>arguments</code> list</p> required"},{"location":"api/plotting/#covvfit.plotting._grid.arrange_into_grid","title":"<code>covvfit.plotting._grid.arrange_into_grid(nplots, ncols=2, axsize=(2.0, 1.0), **kwargs)</code>","text":"<p>Builds an array of plots to accommodate the axes listed.</p> <p>Parameters:</p> Name Type Description Default <code>nplots</code> <code>int</code> <p>number of plots</p> required <code>ncols</code> <code>int</code> <p>number of columns</p> <code>2</code> <code>axsize</code> <code>tuple</code> <p>axis size</p> <code>(2.0, 1.0)</code> <code>kwargs</code> <p>keyword arguments to be passed to <code>subplots_from_axsize</code>. For example, <pre><code>wspace=0.2,  # Changes the horizontal spacing\nhspace=0.3,  # Changes the vertical spacing\nleft=0.5,    # Changes the left margin\n</code></pre></p> <code>{}</code>"},{"location":"api/plotting/#covvfit.plotting._grid.set_axis_off","title":"<code>covvfit.plotting._grid.set_axis_off(ax, i=0, j=0)</code>","text":"<p>Hides the axis.</p>"},{"location":"api/plotting/#timeseries-submodule","title":"Timeseries submodule","text":"<p>Import as </p> <pre><code>from covvfit import plot\nplot_ts = plot.timeseries\n</code></pre>"},{"location":"api/plotting/#covvfit.plot.timeseries.plot_fit","title":"<code>covvfit.plot.timeseries.plot_fit(ax, ts, y_fit, *, colors, variants=None, linestyle='-', **kwargs)</code>","text":"<p>Function to plot fitted values with customizable line type.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>matplotlib.axes</code> <p>The axis to plot on.</p> required <code>ts</code> <code>array-like</code> <p>Time series data.</p> required <code>y_fit</code> <code>array-like</code> <p>Fitted values for each variant.</p> required <code>variants</code> <code>list</code> <p>List of variant names.</p> <code>None</code> <code>colors</code> <code>list</code> <p>List of colors for each variant.</p> required <code>linestyle</code> <code>str</code> <p>Line style for plotting (e.g., '-', '--', '-.', ':').</p> <code>'-'</code>"},{"location":"api/plotting/#covvfit.plot.timeseries.plot_complement","title":"<code>covvfit.plot.timeseries.plot_complement(ax, ts, y_fit, color='grey', linestyle='-', **kwargs)</code>","text":""},{"location":"api/plotting/#covvfit.plot.timeseries.plot_data","title":"<code>covvfit.plot.timeseries.plot_data(ax, ts, ys, colors, size=4.0, alpha=0.5, **kwargs)</code>","text":""},{"location":"api/preprocessing/","title":"Preprocessing","text":"<p>Data preprocessing utilities, used to load deconvoluted data into the model and reshape them into appropriate data formats.</p> <p>Import as:</p> <pre><code>from covvfit import preprocess\n</code></pre>"},{"location":"api/preprocessing/#covvfit.preprocess.TimeScaler","title":"<code> covvfit.preprocess.TimeScaler        </code>","text":"<p>Scales a list of time series, so that the values are normalized.</p>"},{"location":"api/preprocessing/#covvfit.preprocess.TimeScaler.fit","title":"<code>fit(self, ts)</code>","text":"<p>Fit the scaler parameters to the provided time series.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>list</code> <p>list of timeseries, i.e., <code>ts[i]</code> is an array of some length <code>n_timepoints[i]</code>.</p> required"},{"location":"api/preprocessing/#covvfit.preprocess.TimeScaler.fit_transform","title":"<code>fit_transform(self, ts)</code>","text":"<p>Fits the model and returns scaled values.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>list</code> <p>list of timeseries, i.e., <code>ts[i]</code> is an array of some length <code>n_timepoints[i]</code>.</p> required <p>Returns:</p> Type Description <code>list</code> <p>list of exactly the same format as <code>ts</code></p> <p>Note</p> <p>This function is equivalent to calling first <code>fit</code> method and then <code>transform</code>.</p>"},{"location":"api/preprocessing/#covvfit.preprocess.TimeScaler.transform","title":"<code>transform(self, ts)</code>","text":"<p>Returns scaled values.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>list</code> <p>list of timeseries, i.e., <code>ts[i]</code> is an array of some length <code>n_timepoints[i]</code>.</p> required <p>Returns:</p> Type Description <code>list</code> <p>list of exactly the same format as <code>ts</code></p> <p>Note</p> <p>The model has to be fitted first.</p>"},{"location":"api/quasimultinomial/","title":"Quasimultinomial","text":"<p>The quasimultinomial noise model, which corresponds to the high-level Covvfit utilities. It can be imported as:</p> <pre><code>from covvfit import quasimultinomial as qm\n</code></pre> <p>It has the following capabilities:</p>"},{"location":"api/quasimultinomial/#covvfit.quasimultinomial.construct_total_loss","title":"<code>covvfit.quasimultinomial.construct_total_loss(ys, ts, ns=1.0, overdispersion=1.0, accept_theta=True, average_loss=False)</code>","text":"<p>Constructs the loss function, suitable e.g., for optimization.</p> <p>Parameters:</p> Name Type Description Default <code>ys</code> <code>list</code> <p>list of variant proportions for each city. The ith entry should be an array of shape (n_timepoints[i], n_variants)</p> required <code>ts</code> <code>list</code> <p>list of timepoints. The ith entry should be an array of shape (n_timepoints[i],) Note: <code>ts</code> should be appropriately normalized</p> required <code>ns</code> <code>float | list[float] | list[jax.Array] | list[list[float]] | jaxFloat[Array, 'cities']</code> <p>controls the quasimultinomial sample size of each city. It can be:   - a single float (sample size is constant across all cities and timepoints)   - a sequence of floats, describing one sample size for each city   - a list of arrays, with the <code>i</code>th entry having length <code>n_timepoints[i]</code></p> <code>1.0</code> <code>overdispersion</code> <code>float | list[float] | list[jax.Array] | list[list[float]] | jaxFloat[Array, 'cities']</code> <p>controls the overdispersion factor as in the quasilikelihood approach. The shape restrictions are the same as in <code>ns</code>.</p> <code>1.0</code> <code>accept_theta</code> <code>bool</code> <p>whether the returned loss function should accept the <code>theta</code> vector (suitable for optimization) or should be parameterized by the relative growths and relative offsets, as in <pre><code>def loss(\n    relative_growths: array of shape (variants-1,)\n    relative_offsets: array of shape (cities, variants-1)\n) -&gt; float\n</code></pre></p> <code>True</code> <code>average_loss</code> <code>bool</code> <p>whether the loss should be divided by the total number of points. By default it is false, as the loss is used to calculate confidence intervals. Setting it to true can improve the convergence of the optimization procedure</p> <code>False</code> <p>Note</p> <p>The \"loglikelihood\" is effectively rescaled by <code>ns/overdispersion</code> factor. Hence, using both <code>ns</code> and <code>overdispersion</code> should generally be avoided.</p>"},{"location":"api/quasimultinomial/#covvfit.quasimultinomial.construct_model","title":"<code>covvfit.quasimultinomial.construct_model(ys, ts, ns=1.0, overdispersion=1.0, sigma_growth=10.0, sigma_offset=1000.0)</code>","text":"<p>Builds a NumPyro model suitable for sampling from the quasiposterior.</p> <p>Parameters:</p> Name Type Description Default <code>ys</code> <code>list</code> <p>list of variant proportions array for each city. The ith entry should be an array of shape (n_timepoints[i], n_variants)</p> required <code>ts</code> <code>list</code> <p>list of timepoint arrays. The ith entry should be an array of shape (n_timepoints[i],) Note: <code>ts</code> should be appropriately normalized</p> required <code>ns</code> <code>float | list[float] | list[jax.Array] | list[list[float]] | jaxFloat[Array, 'cities']</code> <p>controls the quasimultinomial sample size of each city. It can be:   - a single float (sample size is constant across all cities and timepoints)   - a sequence of floats, describing one sample size for each city   - a list of arrays, with the <code>i</code>th entry having length <code>n_timepoints[i]</code></p> <code>1.0</code> <code>overdispersion</code> <code>float | list[float] | list[jax.Array] | list[list[float]] | jaxFloat[Array, 'cities']</code> <p>controls the overdispersion factor as in the quasilikelihood approach. The shape restrictions are the same as in <code>ns</code>.</p> <code>1.0</code> <code>sigma_growth</code> <code>float</code> <p>controls the standard deviation of the prior on the relative growths</p> <code>10.0</code> <code>sigma_offset</code> <code>float</code> <p>controls the standard deviation of the prior on the relative offsets</p> <code>1000.0</code> <p>Note</p> <p>The \"loglikelihood\" is effectively rescaled by <code>ns/overdispersion</code> factor. Hence, using both <code>ns</code> and <code>overdispersion</code> should generally be avoided.</p>"},{"location":"running_deconv/freyja/","title":"Gather Freyja output for Covvfit analysis","text":"<p>Freyja is a popular tool for deconvolution of wastewater data.</p> <p>As Covvfit requires a CSV file with information about time and location of different measurements, we need to appropriately structure the outputs provided by Freyja.</p> <p>This can be accomplished with a command line utility:</p> <pre><code>covvfit freyja-gather\n</code></pre> <p>TODO: Tutorial to be finished.</p>"},{"location":"running_deconv/lollipop/","title":"Prepare deconvoluted data with LolliPop for Covvfit","text":"<p>Here we explain how to prepare input for Covvfit using the LolliPop tool.</p> <p>We need to deconvolute wastewater data with LolliPop, but we need to do it without smoothing (or with minimal smoothing) to avoid introducing bias by kernel smoothing procedures.</p>"},{"location":"running_deconv/lollipop/#install-lollipop","title":"Install LolliPop","text":"<p>Follow installation instructions described here. They consist of the following: </p> <p>Create environment: <pre><code>conda create -n lollipop \nconda activate lollipop\n</code></pre></p> <p>Clone repository:</p> <pre><code>git clone https://github.com/cbg-ethz/LolliPop.git\ncd LolliPop\n</code></pre> <p>Install dependencies: <pre><code>pip install '.[cli]'\n</code></pre></p>"},{"location":"running_deconv/lollipop/#get-and-prepare-data","title":"Get and prepare data","text":"<p>Make a directory for deconvolution results:</p> <pre><code>mkdir lollipop_covvfit\ncd lollipop_covvfit\n</code></pre> <p>Obtain mutation data, for example from Euler:</p> <pre><code>rsync -avz --progress euler:/cluster/project/pangolin/work-vp-test/variants/tallymut.tsv.zst .\nzstd -d tallymut.tsv.zst \n</code></pre> <p>Obtain the latest configuration files from euler:</p> <pre><code>rsync -avz --progress euler:/cluster/project/pangolin/work-vp-test/var_dates.yaml .\nrsync -avz --progress euler:/cluster/project/pangolin/work-vp-test/variant_config.yaml .\nrsync -avz --progress euler:/cluster/project/pangolin/work-vp-test/ww_locations.tsv .\nrsync -avz --progress euler:/cluster/project/pangolin/work-vp-test/filters_badmut.yaml .\n</code></pre> <p>Prepare parameters for the deconvolution: <pre><code>cat &lt;&lt; EOF &gt; deconv_config.yaml\nbootstrap: 0\n\nkernel_params:\n  bandwidth: 0.1\n\nregressor: robust\nregressor_params:\n  f_scale: 0.01\n\ndeconv_params:\n  min_tol: 1e-3\nEOF\n</code></pre></p>"},{"location":"running_deconv/lollipop/#run-lollipop","title":"Run LolliPop","text":"<p>To deconvolve the data, run:</p> <pre><code>cd ..\nldata=\"./lollipop_covvfit\"\nlollipop deconvolute $ldata/tallymut.tsv \\\n    -o $ldata/deconvolved.csv \\\n    --variants-config $ldata/variant_config.yaml \\\n    --variants-dates $ldata/var_dates.yaml \\\n    --deconv-config $ldata/deconv_config.yaml \\\n    --filters $ldata/filters_badmut.yaml  \\\n    --seed=42 \\\n    --n-cores=2\n</code></pre>"},{"location":"running_deconv/lollipop/#run-covvfit","title":"Run CovvFit","text":"<p>You are ready to use Covvfit and can proceed to the tutorial here.  </p>"}]}